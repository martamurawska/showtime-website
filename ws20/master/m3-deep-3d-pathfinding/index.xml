<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep 3D Pathfinding on IMI Showtime</title>
    <link>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/</link>
    <description>Recent content in Deep 3D Pathfinding on IMI Showtime</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-de</language><atom:link href="https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Features</title>
      <link>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/features/</guid>
      <description>The majority of our time was spent on coming up with new concepts and developing prototypes to test them. Most of our “features” are behind the scenes in our scripts, our model parameters and the general setup. Each machine learning project is different and there are no well known solutions that “just work” for every application. What we present here is only a high level impression of our work, where we summarize the current state and give some details on the prediction quality of our models.</description>
    </item>
    
    <item>
      <title>Process</title>
      <link>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/process/</guid>
      <description>Research Due to the lack of machine learning experience we started our project by researching how machine learning works, what different kinds of concepts exist and which of them are relevant for our path finding problem. Our project supervisors provided us with some useful starting points for this.
The main sources we built upon are GAN Path Finder, Pathfinding via Reinforcement and Imitation Multi-Agent Learning and Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow</description>
    </item>
    
    <item>
      <title>Tech Stack</title>
      <link>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/tech-stack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/tech-stack/</guid>
      <description>Core Technology All machine learning related aspects of our project are built upon Python envionments that were managed with Conda. The reinforcement learning approach uses the TF-Agents library, which is as part of the Tensorflow framework. Our generative adversarial network was created with PyTorch. The machine learning process was accelerated using Nvidia&#39;s CUDA toolkit. The training data generation and result visualization was achieved in Unity with C#. Teamwork To efficiently work as a remote only team, we used Zoom for our meetings and Slack as our text messenger.</description>
    </item>
    
    <item>
      <title>Future</title>
      <link>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/future/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://martamurawska.github.io/showtime-website/ws20/master/m3-deep-3d-pathfinding/future/</guid>
      <description>What is next? The timespan for this project was only sufficient to train the models for a proof of concept stage. With more time and hyperparameter adjustments the quality of the path predictions could be improved. More Concepts As part of our project we also came up with more concepts which have not yet been implemented.
The first is “step by step walking from both directions”. The concept is similar to our current reinforcement learning approach, but it allows parallelisation.</description>
    </item>
    
  </channel>
</rss>
